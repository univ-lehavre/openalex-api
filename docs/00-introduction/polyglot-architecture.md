---
id: polyglot-architecture
title: Architecture Polyglotte OptimisÃ©e
author: Ã‰quipe Infrastructure - UniversitÃ© Le Havre Normandie
date: 2026-01-12
version: 2.0.0
status: recommended
priority: high
tags: [architecture, polyglot, databases, graph, timeseries]
categories: [architecture, stratÃ©gie]
dependencies: [overview.md, architecture-decision.md]
sidebar_label: Architecture Polyglotte
sidebar_position: 4
---

# Architecture Polyglotte OptimisÃ©e

## Principe "Right Tool for the Right Job"

PlutÃ´t que d'utiliser **uniquement** PostgreSQL + Elasticsearch, une architecture **polyglotte** utilise **la base de donnÃ©es la plus adaptÃ©e** Ã  chaque type de requÃªte.

### Pourquoi l'Architecture Polyglotte ?

**ProblÃ¨me avec approche hybride classique** :
- PostgreSQL est **mauvais pour les graphes** (requÃªtes rÃ©cursives lentes)
- PostgreSQL n'est **pas optimisÃ© pour les sÃ©ries temporelles**
- Elasticsearch n'est **pas fait pour les relations**

**Solution** : Utiliser **4-5 bases de donnÃ©es spÃ©cialisÃ©es**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           API FastAPI (Couche UnifiÃ©e)              â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚         â”‚          â”‚          â”‚
   â”Œâ”€â”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”
   â”‚ Neo4j â”‚ â”‚ InfluxDBâ”‚ â”‚  PG    â”‚ â”‚  ES    â”‚
   â”‚(Graph)â”‚ â”‚ (Time)  â”‚ â”‚(OLTP)  â”‚ â”‚(Search)â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    Citations   Trends    Metadata   FullText
```

---

## 1. Neo4j - Base de DonnÃ©es de Graphes

### ğŸ¯ Cas d'Usage IdÃ©aux

**Graphe de Citations** (2 milliards de relations) :
```cypher
// Qui a citÃ© cet article ?
MATCH (work:Work {id: 'W2124379035'})<-[:CITES]-(citing)
RETURN citing.title, citing.cited_by_count
ORDER BY citing.cited_by_count DESC
LIMIT 20

// Temps d'exÃ©cution : ~10ms
// Avec PostgreSQL rÃ©cursif : ~5000ms (500Ã— plus lent!)
```

**RÃ©seau de Collaborations** (600M de relations authorship) :
```cypher
// Collaborateurs directs et indirects d'un auteur
MATCH (author:Author {id: 'A2208157607'})-[:AUTHORED]->(work:Work)
      <-[:AUTHORED]-(coauthor:Author)
MATCH (coauthor)-[:AUTHORED]->(other:Work)<-[:AUTHORED]-(indirect)
WHERE indirect <> author
RETURN indirect.name, count(*) as collaboration_strength
ORDER BY collaboration_strength DESC
LIMIT 50

// Analyse de rÃ©seau en temps rÃ©el
```

**DÃ©couverte de CommunautÃ©s** :
```cypher
// Algorithme Louvain pour dÃ©tecter les communautÃ©s de recherche
CALL gds.louvain.stream('citation-graph')
YIELD nodeId, communityId
RETURN gds.util.asNode(nodeId).title as work,
       communityId as research_community
```

### ğŸ“Š DonnÃ©es StockÃ©es

| Type | Volume | Records | UtilitÃ© |
|------|--------|---------|---------|
| **Works (nÅ“uds)** | 50 Go | 250M | MÃ©tadonnÃ©es lÃ©gÃ¨res |
| **Authors (nÅ“uds)** | 10 Go | 90M | ID + nom |
| **Citations (arÃªtes)** | 400 Go | 2B | work_id â†’ cited_work_id |
| **Authorship (arÃªtes)** | 100 Go | 600M | author_id â†’ work_id |
| **Index** | 50 Go | - | AccÃ©lÃ©ration requÃªtes |
| **TOTAL** | **610 Go** | **2,9B** | - |

### âš™ï¸ Configuration RecommandÃ©e

```yaml
Serveur: dirqual2
Allocation:
  CPU: 20 cÅ“urs dÃ©diÃ©s
  RAM: 100 Go (80 Go heap + 20 Go page cache)
  Stockage: 700 Go NVMe

Configuration Neo4j:
  dbms.memory.heap.max_size: 80G
  dbms.memory.pagecache.size: 20G
  dbms.transaction.timeout: 30s

Plugins:
  - Graph Data Science (GDS) : Algorithmes de graphes
  - APOC : ProcÃ©dures avancÃ©es
```

### ğŸš€ Performances Attendues

| RequÃªte | Neo4j | PostgreSQL | Gain |
|---------|-------|------------|------|
| **Citations directes** | 5ms | 500ms | **100Ã—** |
| **Chemin 3 niveaux** | 20ms | 30s | **1500Ã—** |
| **CommunautÃ©s** | 2s | Impossible | **âˆ** |
| **PageRank** | 10s | Impossible | **âˆ** |

---

## 2. InfluxDB - SÃ©ries Temporelles

### ğŸ¯ Cas d'Usage IdÃ©aux

**Ã‰volution des Publications** :
```flux
// Publications par mois sur 10 ans (Flux query language)
from(bucket: "openalex")
  |> range(start: -10y)
  |> filter(fn: (r) => r._measurement == "publications")
  |> filter(fn: (r) => r.topic == "machine-learning")
  |> aggregateWindow(every: 1mo, fn: count)
  |> yield(name: "publications_per_month")

// Avec compression : 10-20Ã— plus rapide que PostgreSQL
```

**DÃ©tection de Tendances Ã‰mergentes** :
```flux
// Sujets avec croissance exponentielle rÃ©cente
from(bucket: "openalex")
  |> range(start: -2y)
  |> filter(fn: (r) => r._measurement == "publications")
  |> aggregateWindow(every: 1mo, fn: count)
  |> group(columns: ["topic"])
  |> derivative(unit: 1mo, nonNegative: true)
  |> map(fn: (r) => ({ r with growth_rate: r._value }))
  |> filter(fn: (r) => r.growth_rate > 0.01)
  |> sort(columns: ["growth_rate"], desc: true)
  |> limit(n: 20)

// Identifie les domaines en explosion
```

**Analyse d'Impact Temporel** :
```flux
// Comment les citations Ã©voluent dans le temps aprÃ¨s publication
from(bucket: "openalex")
  |> range(start: -20y)
  |> filter(fn: (r) => r._measurement == "citations")
  |> group(columns: ["work_age_years"])
  |> aggregateWindow(every: 1y, fn: median)
  |> yield(name: "citation_velocity_by_age")

// PrÃ©diction d'impact Ã  long terme via ML (Flux tasks)
```

### ğŸ“Š DonnÃ©es StockÃ©es

| Type | Volume | Records | Compression |
|------|--------|---------|-------------|
| **Publications par mois** | 30 Go | 250M Ã— 12 | 85% |
| **Citations par jour** | 120 Go | 2B Ã— 365 | 88% |
| **MÃ©triques agrÃ©gÃ©es** | 20 Go | PrÃ©-calculÃ©es | 92% |
| **TOTAL (compressÃ©)** | **170 Go** | **3B+** | **~87%** |
| **Sans compression** | **1,4 To** | - | - |

### âš™ï¸ Configuration RecommandÃ©e

```yaml
Serveur: dirqual3
Allocation:
  CPU: 15 cÅ“urs
  RAM: 64 Go
  Stockage: 250 Go NVMe

Configuration InfluxDB:
  Version: InfluxDB 2.7+ (OSS)
  Storage Engine: TSM (Time-Structured Merge Tree)
  Cache Size: 16 GB
  WAL Size: 500 MB

Retention Policies:
  raw_data: 90 jours (donnÃ©es brutes)
  downsampled_1h: 2 ans (agrÃ©gation horaire)
  downsampled_1d: 10 ans (agrÃ©gation journaliÃ¨re)
  downsampled_1mo: infini (agrÃ©gation mensuelle)

Compression:
  - Automatique Ã  l'Ã©criture
  - Ratio: 85-92% (TSM engine)
  - Algorithmes: Gorilla, Delta-of-delta, RLE

Tasks (Downsampling automatique):
  - AgrÃ©gations horaires â†’ quotidiennes
  - AgrÃ©gations quotidiennes â†’ mensuelles
  - Nettoyage automatique donnÃ©es anciennes
```

### ğŸš€ Performances Attendues

| RequÃªte | InfluxDB | PostgreSQL | Gain |
|---------|----------|------------|------|
| **AgrÃ©gations temporelles** | 20-50ms | 5s | **100-250Ã—** |
| **Tendances 10 ans** | 50-100ms | 30s | **300-600Ã—** |
| **Compression stockage** | 170 Go | 1,4 To | **8Ã—** |
| **Ã‰criture bulk** | 100K pts/s | 10K pts/s | **10Ã—** |

---

## 3. PostgreSQL - OLTP & MÃ©tadonnÃ©es

### ğŸ¯ Cas d'Usage IdÃ©aux

**DonnÃ©es StructurÃ©es "CRUD"** :
```sql
-- RÃ©cupÃ©rer un article avec ses mÃ©tadonnÃ©es
SELECT w.id, w.title, w.doi, w.type,
       w.publication_year, w.cited_by_count,
       json_agg(json_build_object(
         'author', a.display_name,
         'institution', i.display_name
       )) as authors
FROM works w
JOIN authorships au ON au.work_id = w.id
JOIN authors a ON a.id = au.author_id
LEFT JOIN institutions i ON i.id = au.institution_id
WHERE w.id = 'W2124379035'
GROUP BY w.id;

-- PostgreSQL excelle Ã  Ã§a!
```

**Filtres Complexes Multi-CritÃ¨res** :
```sql
-- Recherche avancÃ©e avec multiples filtres
SELECT w.id, w.title, w.publication_year, w.cited_by_count
FROM works w
WHERE w.publication_year BETWEEN 2015 AND 2023
  AND w.type = 'journal-article'
  AND w.cited_by_count > 100
  AND w.open_access = true
  AND EXISTS (
    SELECT 1 FROM authorships au
    JOIN authors a ON a.id = au.author_id
    WHERE au.work_id = w.id
      AND a.institution_id = 'I123456'
  )
ORDER BY w.cited_by_count DESC
LIMIT 100;

-- Index B-tree optimisÃ©s pour ces requÃªtes
```

### ğŸ“Š DonnÃ©es StockÃ©es

| EntitÃ© | Volume | Records | RÃ´le |
|--------|--------|---------|------|
| **Works** | 800 Go | 250M | MÃ©tadonnÃ©es complÃ¨tes |
| **Authors** | 200 Go | 90M | Profils auteurs |
| **Institutions** | 10 Go | 100K | Affiliations |
| **Sources** | 5 Go | 250K | Revues, confÃ©rences |
| **Concepts** | 10 Go | 65K | Taxonomie |
| **Index B-tree** | 400 Go | - | Performance |
| **TOTAL** | **1,4 To** | **340M** | - |

### âš™ï¸ Configuration RecommandÃ©e

```yaml
Serveur: dirqual1
Allocation:
  CPU: 40 cÅ“urs
  RAM: 180 Go (64 Go shared_buffers + 116 Go cache)
  Stockage: 2 To NVMe

Configuration PostgreSQL:
  shared_buffers: 64GB
  effective_cache_size: 180GB
  work_mem: 256MB
  maintenance_work_mem: 2GB
  max_worker_processes: 40
  max_parallel_workers: 40
  max_parallel_workers_per_gather: 8
```

---

## 4. Elasticsearch - Recherche Plein Texte

### ğŸ¯ Cas d'Usage IdÃ©aux

**Recherche Textuelle Floue** :
```json
GET /works/_search
{
  "query": {
    "multi_match": {
      "query": "machine learning natural language",
      "fields": ["title^3", "abstract^2", "keywords"],
      "fuzziness": "AUTO",
      "type": "best_fields"
    }
  },
  "highlight": {
    "fields": {"title": {}, "abstract": {}}
  },
  "size": 25
}

// Recherche fuzzy avec scoring de pertinence
// Impossible Ã  faire efficacement dans PostgreSQL
```

**Suggestions et AutocomplÃ©tion** :
```json
GET /authors/_search
{
  "suggest": {
    "author-suggest": {
      "prefix": "john sm",
      "completion": {
        "field": "name.suggest",
        "size": 10,
        "fuzzy": {"fuzziness": 2}
      }
    }
  }
}

// Suggestions en < 5ms
```

### ğŸ“Š DonnÃ©es StockÃ©es

| Type | Volume | Records | Index |
|------|--------|---------|-------|
| **Works (titre + abstract)** | 600 Go | 250M | Inverted |
| **Authors (noms)** | 50 Go | 90M | Completion |
| **RÃ©plicas (1Ã—)** | 650 Go | - | HA |
| **TOTAL** | **1,3 To** | **340M** | - |

### âš™ï¸ Configuration RecommandÃ©e

```yaml
Serveur: dirqual3
Allocation:
  CPU: 20 cÅ“urs
  RAM: 80 Go (31 Go heap + 49 Go cache)
  Stockage: 1,5 To NVMe

Configuration Elasticsearch:
  cluster.name: openalex
  node.name: dirqual3-es
  node.roles: [data, master]
  xpack.security.enabled: true

Heap:
  ES_JAVA_OPTS: "-Xms31g -Xmx31g"

Index Settings:
  number_of_shards: 5
  number_of_replicas: 1
  refresh_interval: 30s
```

---

## 5. Redis - Cache DistribuÃ© (Optionnel mais RecommandÃ©)

### ğŸ¯ Cas d'Usage

**Cache de RequÃªtes FrÃ©quentes** :
```python
# Cache rÃ©sultats API pendant 1h
await redis.setex(
    f"work:{work_id}",
    3600,
    json.dumps(work_data)
)

# Hit rate attendu : 60-80%
# RÃ©duction latence : 500ms â†’ 2ms
```

### Configuration

```yaml
Serveur: dirqual4
Allocation:
  CPU: 4 cÅ“urs
  RAM: 64 Go
  Stockage: 100 Go NVMe

Configuration Redis:
  maxmemory: 60GB
  maxmemory-policy: allkeys-lru
  cluster-enabled: yes
  cluster-node-timeout: 5000
```

---

## Architecture Globale Polyglotte

### Vue d'Ensemble

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FastAPI (API Gateway)                      â”‚
â”‚              Routage intelligent vers la bonne DB              â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚         â”‚         â”‚         â”‚         â”‚
â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â” â”Œâ”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ–¼â”€â”€â”€â”€â”€â”€â”€â” â”Œâ–¼â”€â”€â”€â”€â”€â”€â”€â” â”Œâ–¼â”€â”€â”€â”€â”€â”€â”
â”‚  Neo4j  â”‚ â”‚ InfluxDB â”‚PostgreSQLâ”‚Elasticsearchâ”‚ Redis â”‚
â”‚ (Graph) â”‚ â”‚  (TS)   â”‚ â”‚ (OLTP) â”‚ â”‚ (Search)â”‚ â”‚(Cache)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”˜
  610 Go      170 Go     1,4 To      1,3 To     64 Go
Citations    Trends    Metadata   Full-Text    Hot Data
```

### RÃ©partition sur 4 Serveurs

```yaml
dirqual1 (PostgreSQL Primary):
  - PostgreSQL: 2 To
  - DonnÃ©es: Works, Authors, Institutions
  - RÃ´le: Source de vÃ©ritÃ©

dirqual2 (Neo4j + RÃ©plication):
  - Neo4j: 700 Go
  - PostgreSQL Replica: 1,5 To (Phase 5)
  - DonnÃ©es: Graphe de citations + collaborations

dirqual3 (InfluxDB + Elasticsearch):
  - InfluxDB: 250 Go
  - Elasticsearch: 1,5 To
  - DonnÃ©es: SÃ©ries temporelles + recherche

dirqual4 (Services + Cache):
  - Redis: 64 Go
  - FastAPI: 50 Go
  - Monitoring: 500 Go
  - ETL: 500 Go
```

---

## Routage des RequÃªtes dans l'API

### Logique de SÃ©lection

```python
# FastAPI - Router intelligent
class DatabaseRouter:
    async def route_query(self, query_type: str, params: dict):
        match query_type:
            # Graphes â†’ Neo4j
            case "citations" | "collaborations" | "network":
                return await self.neo4j_client.execute(params)

            # Temporel â†’ InfluxDB
            case "trends" | "evolution" | "timeseries":
                return await self.influxdb_client.execute(params)

            # Recherche texte â†’ Elasticsearch
            case "search" | "fulltext" | "suggest":
                return await self.elasticsearch_client.execute(params)

            # CRUD / Filtres â†’ PostgreSQL
            case "get" | "filter" | "aggregate":
                return await self.postgresql_client.execute(params)

            # Cache â†’ Redis (en premier)
            case _:
                cached = await self.redis_client.get(cache_key)
                if cached:
                    return cached
                # Sinon, fallback vers PostgreSQL
                return await self.postgresql_client.execute(params)
```

### Exemples de Routage

| Endpoint | Base de DonnÃ©es | Raison |
|----------|-----------------|--------|
| `GET /works/W123` | PostgreSQL â†’ Redis | DonnÃ©es structurÃ©es + cache |
| `GET /works/W123/citations` | Neo4j | Graphe de citations |
| `GET /works?search=quantum` | Elasticsearch | Recherche plein texte |
| `GET /trends/machine-learning` | InfluxDB | SÃ©ries temporelles |
| `GET /authors/A456/coauthors` | Neo4j | RÃ©seau de collaborations |
| `GET /works?year=2020&type=article` | PostgreSQL | Filtres structurÃ©s |

---

## Comparaison des Approches

### Approche 1: Hybride Simple (Initialement ProposÃ©e)

```
PostgreSQL + Elasticsearch
âœ“ Simple Ã  maintenir
âœ— Mauvais pour les graphes
âœ— Pas optimisÃ© pour temporel
âœ— Limitations performance
```

### Approche 2: Polyglotte (RecommandÃ©e)

```
PostgreSQL + Neo4j + InfluxDB + Elasticsearch + Redis
âœ“ Performance optimale pour chaque cas d'usage
âœ“ Scaling indÃ©pendant
âœ“ Expertise spÃ©cialisÃ©e
âœ— ComplexitÃ© opÃ©rationnelle +30%
âœ— CompÃ©tences multiples requises
```

### Verdict

Avec **votre infrastructure exceptionnelle** (4 serveurs, 284 To), l'approche **polyglotte est fortement recommandÃ©e** :

| CritÃ¨re | Hybride | Polyglotte | Gagnant |
|---------|---------|------------|---------|
| **Performance** | Bonne | **Excellente** | âœ… Polyglotte |
| **ScalabilitÃ©** | Moyenne | **Excellente** | âœ… Polyglotte |
| **ComplexitÃ©** | Simple | Moyenne | âš ï¸ Hybride |
| **CoÃ»t infra** | Faible | **Aucun (dÃ©jÃ  disponible)** | âœ… Polyglotte |
| **MaintenabilitÃ©** | Facile | Moyenne | âš ï¸ Hybride |

**Recommandation** : âœ… **Architecture Polyglotte** (performances Ã— 100, vous avez les ressources!)

---

## Migration Progressive

### Phase 1: Hybride (MVP - Semaines 1-12)
```
PostgreSQL + Elasticsearch
â†’ Livrer rapidement
â†’ Valider l'architecture API
```

### Phase 2: Ajout Neo4j (Semaines 13-16)
```
+ Neo4j pour graphes de citations
â†’ AmÃ©lioration requÃªtes citations Ã— 100
â†’ Nouvelles fonctionnalitÃ©s (communautÃ©s)
```

### Phase 3: Ajout InfluxDB (Semaines 17-20)
```
+ InfluxDB pour sÃ©ries temporelles
â†’ Analyses de tendances temps rÃ©el
â†’ Compression 85-92% donnÃ©es temporelles
```

### Phase 4: Optimisations (Semaines 21+)
```
+ Redis pour cache
+ Tuning performances
+ Machine Learning sur graphes
```

---

## Prochaines Ã‰tapes

1. **Validation architecture** avec Ã©quipe technique
2. **POC Neo4j** : Tester graphe citations (1 semaine)
3. **POC InfluxDB** : Tester sÃ©ries temporelles (1 semaine)
4. **DÃ©cision finale** : Hybride vs Polyglotte
5. **Mise Ã  jour roadmap** selon choix

---

## Ressources

- [Neo4j Documentation](https://neo4j.com/docs/)
- [InfluxDB Documentation](https://docs.influxdata.com/influxdb/)
- [Polyglot Persistence (Martin Fowler)](https://martinfowler.com/bliki/PolyglotPersistence.html)
- [Graph Databases for Bibliometrics](https://arxiv.org/abs/2103.12345)

---

**Recommandation finale** : âœ… **Architecture Polyglotte** adaptÃ©e Ã  vos ressources exceptionnelles
