---
id: backup-recovery
title: Sauvegardes et R√©cup√©ration
author: √âquipe Infrastructure - Universit√© Le Havre Normandie
date: 2026-01-12
version: 0.1.0
status: draft
priority: high
tags: [backup, r√©cup√©ration, disaster-recovery, haute-disponibilit√©]
sidebar_label: Backup & Recovery
sidebar_position: 8
---

# Sauvegardes et R√©cup√©ration

‚ö†Ô∏è **Documentation en cours de r√©daction**

## Contexte

La strat√©gie de sauvegarde doit prot√©ger contre :
- **Erreurs humaines** : Suppression accidentelle, mauvaise requ√™te
- **Corruption de donn√©es** : Bugs applicatifs, erreurs de traitement
- **Pannes mat√©rielles** : Perte de n≈ìud Kubernetes, d√©faillance stockage
- **Sinistres** : Incendie, inondation, ransomware

**Note importante** : Les donn√©es sources OpenAlex n'ont **pas besoin d'√™tre sauvegard√©es** car elles sont toujours disponibles en ligne via l'API et les snapshots AWS S3.

## Objectifs

- [ ] Strat√©gie de backup diff√©renci√©e par base de donn√©es
- [ ] RPO (Recovery Point Objective) : < 24h
- [ ] RTO (Recovery Time Objective) : < 4h
- [ ] Stockage des backups sur Ceph RGW (S3-compatible)
- [ ] Tests de restauration r√©guliers (mensuel)
- [ ] Automatisation avec CronJobs Kubernetes

## Strat√©gie par Base de Donn√©es

### PostgreSQL - pgBackRest

**M√©thode** : Backups incr√©mentaux avec pgBackRest

```yaml
Backup Type: Full + Incremental
Frequency:
  - Full backup: Hebdomadaire (Dimanche 2h00)
  - Incremental backup: Quotidien (2h00)
Retention: 30 jours
Storage: Ceph RGW bucket postgres-backups
Size: ~1.5 TB (full) + ~50-100 GB/jour (incremental)
```

**Configuration pgBackRest** :
```ini
[global]
repo1-type=s3
repo1-s3-endpoint=rook-ceph-rgw.rook-ceph.svc
repo1-s3-bucket=postgres-backups
repo1-s3-region=us-east-1
repo1-retention-full=4
repo1-retention-diff=8

[openalex]
pg1-path=/var/lib/postgresql/data
```

**Commandes** :
```bash
# Backup complet
pgbackrest --stanza=openalex --type=full backup

# Backup incr√©mental
pgbackrest --stanza=openalex --type=incr backup

# Restauration
pgbackrest --stanza=openalex restore
```

### Neo4j - neo4j-admin backup

**M√©thode** : Snapshots avec neo4j-admin

```yaml
Backup Type: Full backup
Frequency: Quotidien (3h00)
Retention: 14 jours
Storage: Ceph RGW bucket neo4j-backups
Size: ~610 GB par backup (compress√© ~300 GB)
```

**Commandes** :
```bash
# Backup
neo4j-admin database backup --database=openalex \
  --to-path=/backups/$(date +%Y%m%d)

# Compression et upload vers S3
tar -czf neo4j-backup-$(date +%Y%m%d).tar.gz /backups/$(date +%Y%m%d)
aws s3 cp neo4j-backup-$(date +%Y%m%d).tar.gz s3://neo4j-backups/

# Restauration
neo4j-admin database restore --from-path=/backups/20240115
```

### InfluxDB - Snapshots

**M√©thode** : Snapshots InfluxDB

```yaml
Backup Type: Full snapshot
Frequency: Quotidien (3h30)
Retention: 14 jours
Storage: Ceph RGW bucket influxdb-backups
Size: ~170 GB par backup (compress√© ~100 GB)
```

**Commandes** :
```bash
# Backup
influx backup /backups/$(date +%Y%m%d) \
  --host http://influxdb:8086

# Upload vers S3
tar -czf influxdb-backup-$(date +%Y%m%d).tar.gz /backups/$(date +%Y%m%d)
aws s3 cp influxdb-backup-$(date +%Y%m%d).tar.gz s3://influxdb-backups/

# Restauration
influx restore /backups/20240115 \
  --host http://influxdb:8086
```

### Elasticsearch - Snapshots Repository

**M√©thode** : Snapshots natifs Elasticsearch

```yaml
Backup Type: Incremental snapshots
Frequency: Quotidien (4h00)
Retention: 14 jours
Storage: Ceph RGW bucket elasticsearch-snapshots
Size: ~1.3 TB (premier snapshot) + ~50-100 GB/jour (incr√©mental)
```

**Configuration** :
```json
PUT _snapshot/s3_repository
{
  "type": "s3",
  "settings": {
    "bucket": "elasticsearch-snapshots",
    "endpoint": "rook-ceph-rgw.rook-ceph.svc",
    "protocol": "http",
    "compress": true
  }
}
```

**Commandes** :
```bash
# Cr√©er un snapshot
PUT _snapshot/s3_repository/snapshot_$(date +%Y%m%d)
{
  "indices": "*",
  "ignore_unavailable": true,
  "include_global_state": false
}

# Restaurer
POST _snapshot/s3_repository/snapshot_20240115/_restore
```

### Redis - RDB Snapshots

**Note** : Redis est un cache. Pas de backup n√©cessaire (donn√©es reconstruites depuis PostgreSQL/Neo4j).

```yaml
Persistence: RDB snapshots (pour red√©marrage rapide)
Frequency: Toutes les 1h (si > 1000 changements)
Storage: Local (PVC NVMe)
Size: ~64 GB
```

## Calendrier de Sauvegarde

| Heure | PostgreSQL | Neo4j | InfluxDB | Elasticsearch |
|-------|-----------|-------|----------|---------------|
| 02:00 | ‚úÖ Incr/Full | - | - | - |
| 03:00 | - | ‚úÖ Full | - | - |
| 03:30 | - | - | ‚úÖ Full | - |
| 04:00 | - | - | - | ‚úÖ Snapshot |

**Total espace backup (par jour)** :
- PostgreSQL: 50-100 GB (incr√©mental)
- Neo4j: 300 GB (compress√©)
- InfluxDB: 100 GB (compress√©)
- Elasticsearch: 50-100 GB (incr√©mental)
- **Total** : ~500-600 GB/jour

**R√©tention 30 jours** : ~15-18 TB sur Ceph RGW

## Proc√©dures de Restauration

### Restauration PostgreSQL (RTO: 2-3h)

```bash
# 1. Arr√™ter PostgreSQL
kubectl scale statefulset postgres --replicas=0

# 2. Restaurer avec pgBackRest
pgbackrest --stanza=openalex --type=time \
  --target="2024-01-15 14:30:00" restore

# 3. Red√©marrer PostgreSQL
kubectl scale statefulset postgres --replicas=1

# 4. V√©rifier
psql -c "SELECT COUNT(*) FROM works;"
```

### Restauration Neo4j (RTO: 1-2h)

```bash
# 1. Arr√™ter Neo4j
kubectl scale statefulset neo4j --replicas=0

# 2. T√©l√©charger le backup
aws s3 cp s3://neo4j-backups/neo4j-backup-20240115.tar.gz .
tar -xzf neo4j-backup-20240115.tar.gz

# 3. Restaurer
neo4j-admin database restore --from-path=/backups/20240115

# 4. Red√©marrer Neo4j
kubectl scale statefulset neo4j --replicas=1
```

### Restauration Compl√®te (RTO: 4h)

1. Restaurer PostgreSQL (2-3h)
2. Restaurer Neo4j en parall√®le (1-2h)
3. Restaurer InfluxDB en parall√®le (30min)
4. Restaurer Elasticsearch en parall√®le (1h)
5. Reconstruire Redis cache (automatique)

**Total** : ~4h (parall√©lisation)

## Tests de Restauration

```yaml
Fr√©quence: Mensuel (premier dimanche du mois)
Environnement: Cluster de test d√©di√©
Proc√©dure:
  1. Restaurer tous les backups sur cluster test
  2. V√©rifier l'int√©grit√© des donn√©es
  3. Tester les requ√™tes API
  4. Mesurer les temps de restauration (RTO)
  5. Documenter les anomalies
```

## Automatisation avec Kubernetes CronJobs

```yaml
# Example: CronJob PostgreSQL Backup
apiVersion: batch/v1
kind: CronJob
metadata:
  name: postgres-backup
spec:
  schedule: "0 2 * * *"  # Tous les jours √† 2h00
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: pgbackrest
            image: pgbackrest/pgbackrest:latest
            command: ["/bin/sh", "-c"]
            args:
              - pgbackrest --stanza=openalex --type=incr backup
            env:
              - name: PGBACKREST_REPO1_S3_ENDPOINT
                value: rook-ceph-rgw.rook-ceph.svc
          restartPolicy: OnFailure
```

## Prochaines √âtapes

1. Impl√©menter les CronJobs Kubernetes pour chaque base
2. Configurer Ceph RGW et cr√©er les buckets S3
3. Tester la proc√©dure compl√®te de backup/restore
4. Automatiser les tests de restauration mensuels
5. Documenter les proc√©dures d'urgence

## R√©f√©rences

- [Configuration Rook/Ceph](./rook-ceph.md)
- [Strat√©gie de stockage globale](./strategy.md)
- [Plan de reprise apr√®s sinistre](../09-operations/disaster-recovery.md)

---

**Statut** : üìù Brouillon - √Ä compl√©ter avec CronJobs, scripts de restauration, et runbook
